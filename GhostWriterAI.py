import streamlit as st
import openai
import os
import json
import numpy as np
from datetime import datetime
import trafilatura
from youtube_transcript_api import YouTubeTranscriptApi
from googlesearch import search
from sentence_transformers import SentenceTransformer, util

# === C·∫•u h√¨nh OpenAI ===
client = openai.OpenAI()
st.set_page_config(page_title="GhostWriter AI", layout="wide")

STYLE_SAMPLE_DIR = "my_style_samples"
model_embed = SentenceTransformer("all-MiniLM-L6-v2")

# === SESSION STATE ===
if "hook" not in st.session_state:
    st.session_state.hook = ""
if "sections" not in st.session_state:
    st.session_state.sections = []
if "sources" not in st.session_state:
    st.session_state.sources = []
if "structure_titles" not in st.session_state:
    st.session_state.structure_titles = []
if "source_vectors" not in st.session_state:
    st.session_state.source_vectors = []

# === C√ÅC TONE PHONG C√ÅCH ƒê·ªäNH S·∫¥N ===
persona_tones = {
    "Gi√°o s∆∞ ch√¢m bi·∫øm": "witty, sarcastic, intellectually playful",
    "ASMR nh·∫π nh√†ng": "calm, sensory, soothing and immersive",
    "H√†i h∆∞·ªõc ph√≥ng ƒë·∫°i": "goofy, absurd, highly exaggerated and comedic",
    "K·ªÉ nh∆∞ b·∫°n th√¢n": "casual, relatable, conversational",
    "Kinh d·ªã th√¨ th·∫ßm": "dark, suspenseful, vivid and unsettling",
    "S·ª≠ chu·∫©n gi√°o s∆∞": "formal, precise, informative",
    "Tri·∫øt l√Ω huy·ªÅn b√≠": "poetic, reflective, symbolic and deep"
}

# === STYLE VECTOR ===
def list_available_style_vectors():
    return [f for f in os.listdir() if f.startswith("my_style_vector") and f.endswith(".json")]

def load_style_vector_from_file(file):
    with open(file, "r", encoding="utf-8") as f:
        return np.array(json.load(f))

# === TMProxy cache h·ªó tr·ª£ ===
def get_tmproxy_with_cache(api_key):
    import requests
    import time

    if "tmproxy" not in st.session_state:
        st.session_state.tmproxy = {}

    cache = st.session_state.tmproxy
    now = time.time()

    # N·∫øu c√≤n hi·ªáu l·ª±c th√¨ d√πng l·∫°i
    if cache and now < cache.get("expires_at", 0) - 30:
        return cache["proxy_url"]

    try:
        url = "https://tmproxy.com/api/proxy/get-new-proxy"
        headers = {"accept": "application/json", "Content-Type": "application/json"}
        data = {"api_key": api_key, "id_location": 0, "id_isp": 0}

        res = requests.post(url, headers=headers, json=data, timeout=10)
        res.raise_for_status()
        res_json = res.json()

        # N·∫øu th√†nh c√¥ng ‚Üí l∆∞u v√† tr·∫£ proxy m·ªõi
        if res_json["code"] == 0:
            proxy = res_json["data"]
            proxy_url = f"http://{proxy['username']}:{proxy['password']}@{proxy['https']}"
            expires_at = now + proxy["timeout"]

            st.session_state.tmproxy = {
                "proxy_url": proxy_url,
                "expires_at": expires_at
            }

            return proxy_url

        # N·∫øu b·ªã gi·ªõi h·∫°n th·ªùi gian ‚Üí d√πng l·∫°i proxy c≈© n·∫øu c√≥
        elif "retry after" in res_json.get("message", "").lower():
            if cache.get("proxy_url"):
                wait_msg = res_json["message"]
                st.info(f"üîÅ {wait_msg}. ƒêang d√πng l·∫°i proxy c≈©.")
                return cache["proxy_url"]
            else:
                raise Exception(f"TMProxy ch∆∞a c√≥ proxy tr∆∞·ªõc ƒë√≥ ƒë·ªÉ d√πng l·∫°i.")

        else:
            raise Exception(f"TMProxy Error: {res_json.get('message')}")

    except Exception as e:
        st.error(f"‚ùå Kh√¥ng th·ªÉ l·∫•y proxy t·ª´ TMProxy: {e}")
        return None

# === GIAO DI·ªÜN CH√çNH ===
st.title("üìù GhostWriter AI")
topic = st.text_input("üéØ Nh·∫≠p ch·ªß ƒë·ªÅ ho·∫∑c n·ªôi dung video:")
pov_choice = st.selectbox("üë§ Ch·ªçn ng√¥i k·ªÉ:", ["first", "second", "third"], index=1)

selected_personas = st.multiselect("üé≠ Ch·ªçn c√°c phong c√°ch h√†nh vƒÉn mu·ªën k·∫øt h·ª£p:", list(persona_tones.keys()))
style_tone_instruction = ", ".join([persona_tones[p] for p in selected_personas]) if selected_personas else ""
strong_tone_prompt = ""
if style_tone_instruction:
    strong_tone_prompt = (
        f"Write this section in a distinctly {style_tone_instruction} tone.\n"
        f"Channel the spirit of a narrator who embodies these traits in full.\n"
        f"Avoid solemn or overly poetic language unless it enhances the comedic or satirical effect."
    )

# === NGU·ªíN THAM KH·∫¢O GOOGLE ===
if st.button("üîé T√¨m link Google"):
    with st.spinner("ƒêang t√¨m ki·∫øm tr√™n Google..."):
        try:
            results = list(search(topic, num_results=25))
            st.session_state.sources = []
            st.session_state.search_links = results
        except Exception as e:
            st.error(f"L·ªói Google Search: {e}")

if "search_links" in st.session_state:
    selected_links = st.multiselect("Ch·ªçn link ƒë·ªÉ tr√≠ch n·ªôi dung:", st.session_state.search_links)
    if st.button("üìÑ Tr√≠ch n·ªôi dung t·ª´ link ƒë√£ ch·ªçn"):
        try:
            proxy_url = get_tmproxy_with_cache("tmproxy_api_key")
            proxy_dict = {"http": proxy_url, "https": proxy_url}
            session = requests.Session()
            session.proxies.update(proxy_dict)

            for link in selected_links:
                try:
                    downloaded = trafilatura.fetch_url(link, request_kwargs={"session": session})
                    text = trafilatura.extract(downloaded)
                    if text:
                        st.session_state.sources.append(f"[SOURCE: {link}]\n{text.strip()}")
                    else:
                        st.warning(f"‚ö†Ô∏è Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c n·ªôi dung t·ª´: {link}")
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è L·ªói v·ªõi {link}: {e}")
            build_reference_vectors()
            st.success("‚úÖ ƒê√£ t·∫°o vector t·ª´ ngu·ªìn tham kh·∫£o!")
        except Exception as e:
            st.error(f"‚ùå L·ªói proxy khi tr√≠ch Google: {e}")

# === L·∫§Y CAPTION YOUTUBE ===
from urllib.parse import urlparse, parse_qs
from youtube_transcript_api import YouTubeTranscriptApi

yt_url = st.text_input("Link YouTube")

if st.button("üé¨ L·∫•y caption") and yt_url:
    try:
        video_id = parse_qs(urlparse(yt_url).query).get("v", [""])[0]  # <== d√≤ng thi·∫øu
        proxies = {"http": proxy_url, "https": proxy_url}              # TMProxy proxy_url l·∫•y ·ªü tr√™n

        transcript = YouTubeTranscriptApi.get_transcript(video_id, proxies=proxies)
        full_text = " ".join([x['text'] for x in transcript])

        st.session_state.sources.append(f"[YOUTUBE] {full_text}")
        build_reference_vectors()
        st.success("‚úÖ ƒê√£ l·∫•y caption t·ª´ YouTube!")
    except Exception as e:
        st.error(f"‚ùå L·ªói l·∫•y caption: {e}")

# === BUILD VECTOR ===
def build_reference_vectors():
    chunks = []
    for src in st.session_state.sources:
        paragraphs = src.split("\n")
        for p in paragraphs:
            p = p.strip()
            if 100 < len(p) < 1000:
                chunks.append(p)
    st.session_state.source_vectors = [
        (text, model_embed.encode(text, convert_to_tensor=False)) for text in chunks
    ]

def select_relevant_sources(title, top_k=1):
    title_vec = model_embed.encode(title, convert_to_tensor=False)
    scores = [(text, float(util.cos_sim(title_vec, vec))) for text, vec in st.session_state.source_vectors]
    scores.sort(key=lambda x: -x[1])
    return "\n\n".join([s[0] for s in scores[:top_k]])


# === T·∫†O HOOK ===
st.markdown("---")
st.subheader("‚ú® Vi·∫øt Hook m·ªü ƒë·∫ßu video")
if st.button("üß† T·∫°o Hook m·ªü ƒë·∫ßu"):
    with st.spinner("ƒêang t·∫°o hook..."):
        refs = "\n\n".join(st.session_state.sources)
        prompt = f"""
You are a creative ASMR-style content writer. Write a vivid, immersive, slightly witty YouTube hook intro for:
"{topic}"
References:
{refs}

Follow this format:
- Open with "Hey guys, tonight we..."
- Use vivid sensory imagery
- Include a funny warning: "you probably won't survive this..."
- End with a cozy CTA to like & relax
"""
        try:
            res = client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=500
            )
            st.session_state.hook = res.choices[0].message.content.strip()
        except Exception as e:
            st.error(f"‚ùå GPT Error khi t·∫°o hook: {e}")

st.text_area("‚ú® Hook m·ªü ƒë·∫ßu:", st.session_state.hook, height=150, key="hook_textarea")

# === G·ª¢I √ù C·∫§U TR√öC N·ªòI DUNG ===
st.markdown("---")
st.subheader("üìö G·ª£i √Ω c·∫•u tr√∫c n·ªôi dung")
num_sections = st.slider("üìë S·ªë l∆∞·ª£ng section mong mu·ªën:", min_value=3, max_value=10, value=6, step=1)

if st.button("‚öôÔ∏è G·ª£i √Ω l·∫°i c·∫•u tr√∫c"):
    with st.spinner("ƒêang sinh c·∫•u tr√∫c ƒë·ªÅ xu·∫•t..."):
        refs = "\n\n".join(st.session_state.sources)
        prompt = f"""
You are a YouTube script planner. Based on the topic below, generate a hook and exactly {num_sections} section titles in order.

Only return pure JSON. No explanation. Format:
{{
  "hook": "...",
  "sections": ["...", "...", "..."]
}}

Topic: {topic}
References:
{refs}
"""
        try:
            res = client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.6,
                max_tokens=1000
            )
            raw = res.choices[0].message.content.strip()
            if raw.startswith("```"):
                raw = raw.strip("`").strip()
                if raw.lower().startswith("json"):
                    raw = raw[4:].strip()
            parsed = json.loads(raw)
            st.session_state.hook = parsed.get("hook", "")
            st.session_state.structure_titles = parsed.get("sections", [])
        except Exception as e:
            st.error("‚ùå GPT tr·∫£ v·ªÅ kh√¥ng ƒë√∫ng JSON ho·∫∑c l·ªói khi ph√¢n t√≠ch:")
            st.code(raw)

# === SECTION TI√äU ƒê·ªÄ ===
if st.session_state.structure_titles:
    st.markdown("#### üß± Ti√™u ƒë·ªÅ c√°c section (c√≥ th·ªÉ ch·ªânh s·ª≠a ho·∫∑c xo√°):")
    for i, title in enumerate(st.session_state.structure_titles):
        col1, col2 = st.columns([5, 1])
        with col1:
            st.session_state.structure_titles[i] = st.text_input(f"Section {i+1} Title", title, key=f"title_{i}")
        with col2:
            if st.button("‚ùå", key=f"del_{i}"):
                st.session_state.structure_titles.pop(i)
                st.experimental_rerun()

# === VI·∫æT N·ªòI DUNG M·ªñI SECTION ===
st.markdown("---")
st.subheader("‚úçÔ∏è Vi·∫øt n·ªôi dung t·ª´ng Section")
style_files = list_available_style_vectors()
selected_style_file = st.selectbox("üé® Ch·ªçn phong c√°ch c√° nh√¢n:", style_files if style_files else ["Kh√¥ng t√¨m th·∫•y vector"])
word_count = st.slider("üî§ S·ªë l∆∞·ª£ng t·ª´ m·ªói section:", 100, 3000, 500, step=100)

if st.session_state.structure_titles:
    for idx, title in enumerate(st.session_state.structure_titles):
        if st.button(f"‚úçÔ∏è Vi·∫øt Section {idx+1}: {title}", key=f"gen_{idx}"):
            try:
                with st.spinner("ƒêang vi·∫øt section..."):
                    vector = load_style_vector_from_file(selected_style_file)
                    references = select_relevant_sources(title)
                    prev_title = st.session_state.sections[idx - 1]["title"] if idx > 0 and idx <= len(st.session_state.sections) else None
                    prev_content = st.session_state.sections[idx - 1]["user_edit"] if idx > 0 and idx <= len(st.session_state.sections) else None
                    examples = get_style_examples(vector)

                    prompt_parts = [
                        "You are a writing assistant trained to match this personal narrative style.",
                        "Here are example paragraphs:\n" + "\n\n".join(examples),
                        "------------------------",
                        f"Hook: {st.session_state.hook}"
                    ]
                    if prev_title and prev_content:
                        prompt_parts.append("You are continuing a multi-part narrative script.")
                        prompt_parts.append(f"Previous Section Title: {prev_title}")
                        prompt_parts.append(f"Previous Section Content: {prev_content[:600]}")
                    prompt_parts.append(f"Now, write the next section titled: '{title}'")
                    prompt_parts.append(f"References:\n{references}")
                    if strong_tone_prompt:
                        prompt_parts.append(strong_tone_prompt)
                    prompt_parts.append(
                        f"Write a vivid, immersive section of about {word_count} words in the same tone. "
                        f"Use {pov_choice} person point of view. Do NOT repeat the section title. Do NOT include the title in the content."
                    )

                    full_prompt = "\n\n".join(prompt_parts)
                    res = client.chat.completions.create(
                        model="gpt-4o",
                        messages=[{"role": "user", "content": full_prompt}],
                        temperature=0.7,
                        max_tokens=min(int(word_count * 1.5), 6000)
                    )
                    output = res.choices[0].message.content.strip()
                    if idx < len(st.session_state.sections):
                        st.session_state.sections[idx]["user_edit"] = output
                        st.session_state.sections[idx]["title"] = title
                    else:
                        st.session_state.sections.append({
                            "title": title,
                            "user_edit": output
                        })
            except Exception as e:
                st.error(f"‚ùå GPT Error: {e}")

# === HI·ªÇN TH·ªä SECTION ===
for i, sec in enumerate(st.session_state.sections):
    st.markdown(f"### üì¶ {sec['title']}")
    sec["user_edit"] = st.text_area(f"Section {i+1} - C√≥ th·ªÉ ch·ªânh s·ª≠a t·∫°i ƒë√¢y:", sec["user_edit"], height=250, key=f"edit_{i}")

# === XU·∫§T TO√ÄN B·ªò ===
st.markdown("---")
if st.session_state.sections:
    full_text = st.session_state.hook + "\n\n"
    for sec in st.session_state.sections:
        full_text += f"{sec['title']}\n{sec['user_edit']}\n\n"

    filename = f"ghostwriter_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"

    st.download_button(
        label="üì• T·∫£i to√†n b·ªô n·ªôi dung (.txt)",
        data=full_text,
        file_name=filename,
        mime="text/plain"
    )

