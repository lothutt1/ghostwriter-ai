import streamlit as st
import openai
import os
import json
import numpy as np
from datetime import datetime
import trafilatura
from youtube_transcript_api import YouTubeTranscriptApi
from googlesearch import search
from sentence_transformers import SentenceTransformer, util

# === C·∫•u h√¨nh OpenAI ===
client = openai.OpenAI()
st.set_page_config(page_title="GhostWriter AI", layout="wide")

STYLE_SAMPLE_DIR = "my_style_samples"
model_embed = SentenceTransformer("all-MiniLM-L6-v2", device='cpu')


# === SESSION STATE ===
if "hook" not in st.session_state:
    st.session_state.hook = ""
if "sections" not in st.session_state:
    st.session_state.sections = []
if "sources" not in st.session_state:
    st.session_state.sources = []
if "structure_titles" not in st.session_state:
    st.session_state.structure_titles = []
if "source_vectors" not in st.session_state:
    st.session_state.source_vectors = []

# === C√ÅC TONE PHONG C√ÅCH ƒê·ªäNH S·∫¥N ===
persona_tones = {
    "Gi√°o s∆∞ ch√¢m bi·∫øm": "witty, sarcastic, intellectually playful",
    "ASMR nh·∫π nh√†ng": "calm, sensory, soothing and immersive",
    "H√†i s·ª≠ b·ª±a": "goofy, absurd, highly exaggerated and comedic",
    "K·ªÉ nh∆∞ b·∫°n th√¢n": "casual, relatable, conversational",
    "Kinh d·ªã l·ªãch s·ª≠": "dark, suspenseful, vivid and unsettling",
    "S·ª≠ chu·∫©n s√°ch gi√°o khoa": "formal, precise, informative",
    "Tri·∫øt l√Ω ph·∫£n t∆∞": "poetic, reflective, symbolic and deep"
}

# === STYLE VECTOR ===
def list_available_style_vectors():
    return [f for f in os.listdir() if f.startswith("my_style_vector") and f.endswith(".json")]

def load_style_vector_from_file(file):
    with open(file, "r", encoding="utf-8") as f:
        return np.array(json.load(f)["personal_style_vector"], dtype=np.float32)

def get_style_examples(vector, k=2):
    examples = []
    for fname in os.listdir(STYLE_SAMPLE_DIR):
        if fname.endswith(".txt"):
            with open(os.path.join(STYLE_SAMPLE_DIR, fname), "r", encoding="utf-8") as f:
                text = f.read().strip()
                if text:
                    vec = model_embed.encode(text)
                    sim = util.cos_sim(vec, vector)[0][0].item()
                    examples.append((text, sim))
    examples.sort(key=lambda x: -x[1])
    return [e[0] for e in examples[:k]]

def build_reference_vectors():
    chunks = []
    for src in st.session_state.sources:
        paragraphs = src.split("\n")
        for p in paragraphs:
            p = p.strip()
            if 100 < len(p) < 1000:
                chunks.append(p)
    st.session_state.source_vectors = [(text, model_embed.encode(text)) for text in chunks]

def select_relevant_sources(title, top_k=1):
    title_vec = model_embed.encode(title)
    scores = [(text, float(util.cos_sim(title_vec, vec))) for text, vec in st.session_state.source_vectors]
    scores.sort(key=lambda x: -x[1])
    return "\n\n".join([s[0] for s in scores[:top_k]])

# === GIAO DI·ªÜN CH√çNH ===
st.title("üìù GhostWriter AI")
topic = st.text_input("üéØ Nh·∫≠p ch·ªß ƒë·ªÅ ho·∫∑c n·ªôi dung video:")
pov_choice = st.selectbox("üë§ Ch·ªçn ng√¥i k·ªÉ:", ["first", "second", "third"], index=1)

selected_personas = st.multiselect("üé≠ Ch·ªçn c√°c phong c√°ch h√†nh vƒÉn mu·ªën k·∫øt h·ª£p:", list(persona_tones.keys()))
style_tone_instruction = ", ".join([persona_tones[p] for p in selected_personas]) if selected_personas else ""
strong_tone_prompt = ""
if style_tone_instruction:
    strong_tone_prompt = (
        f"Write this section in a distinctly {style_tone_instruction} tone.\n"
        f"Channel the spirit of a narrator who embodies these traits in full.\n"
        f"Avoid solemn or overly poetic language unless it enhances the comedic or satirical effect."
    )


# === NGU·ªíN THAM KH·∫¢O ===
if st.button("üîé T√¨m link Google"):
    with st.spinner("ƒêang t√¨m ki·∫øm tr√™n Google..."):
        try:
            results = list(search(topic, num_results=10))
            st.session_state.sources = []
            st.session_state.search_links = results
        except Exception as e:
            st.error(f"L·ªói Google Search: {e}")

if "search_links" in st.session_state:
    selected_links = st.multiselect("Ch·ªçn link ƒë·ªÉ tr√≠ch n·ªôi dung:", st.session_state.search_links)
    if st.button("üìÑ Tr√≠ch n·ªôi dung t·ª´ link ƒë√£ ch·ªçn"):
        for link in selected_links:
            try:
                downloaded = trafilatura.fetch_url(link)
                text = trafilatura.extract(downloaded)
                if text:
                    st.session_state.sources.append(f"[SOURCE: {link}]\n{text.strip()}")
                else:
                    st.warning(f"‚ö†Ô∏è Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c n·ªôi dung t·ª´: {link}")
            except Exception as e:
                st.warning(f"‚ö†Ô∏è L·ªói v·ªõi {link}: {e}")
        build_reference_vectors()
        st.success("‚úÖ ƒê√£ t·∫°o vector t·ª´ ngu·ªìn tham kh·∫£o!")

yt_url = st.text_input("Link YouTube")
if st.button("üé¨ L·∫•y caption") and yt_url:
    try:
        video_id = yt_url.split("v=")[1].split("&")[0]
        transcript = YouTubeTranscriptApi.get_transcript(video_id)
        full_text = " ".join([x['text'] for x in transcript])
        st.session_state.sources.append(f"[YOUTUBE] {full_text}")
        build_reference_vectors()
        st.success("ƒê√£ l·∫•y caption v√† t·∫°o vector t·ª´ ngu·ªìn!")
    except Exception as e:
        st.error(f"‚ùå L·ªói l·∫•y caption: {e}")

# === T·∫†O HOOK RI√äNG ===
st.markdown("---")
st.subheader("‚ú® Vi·∫øt Hook m·ªü ƒë·∫ßu video")
if st.button("üß† T·∫°o Hook m·ªü ƒë·∫ßu"):
    with st.spinner("ƒêang t·∫°o hook..."):
        refs = "\n\n".join(st.session_state.sources)
        prompt = f"""
You are a creative ASMR-style content writer. Write a vivid, immersive, slightly witty YouTube hook intro for:
"{topic}"
References:
{refs}

Follow this format:
- Open with "Hey guys, tonight we..."
- Use vivid sensory imagery
- Include a funny warning: "you probably won't survive this..."
- End with a cozy CTA to like & relax
"""
        try:
            res = client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=500
            )
            st.session_state.hook = res.choices[0].message.content.strip()
        except Exception as e:
            st.error(f"‚ùå GPT Error khi t·∫°o hook: {e}")

st.text_area("‚ú® Hook m·ªü ƒë·∫ßu:", st.session_state.hook, height=150, key="hook_textarea")

# === C·∫§U TR√öC SECTION ===
st.markdown("---")
st.subheader("üìö G·ª£i √Ω c·∫•u tr√∫c n·ªôi dung")
num_sections = st.slider("üìë S·ªë l∆∞·ª£ng section mong mu·ªën:", min_value=3, max_value=10, value=6, step=1)

if st.button("‚öôÔ∏è G·ª£i √Ω l·∫°i c·∫•u tr√∫c"):
    with st.spinner("ƒêang sinh c·∫•u tr√∫c ƒë·ªÅ xu·∫•t..."):
        refs = "\n\n".join(st.session_state.sources)
        prompt = f"""
You are a YouTube script planner. Based on the topic below, generate a hook and exactly {num_sections} section titles in order.

Only return pure JSON. No explanation. Format:
{{
  "hook": "...",
  "sections": ["...", "...", "..."]
}}

Topic: {topic}
References:
{refs}
"""
        try:
            res = client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.6,
                max_tokens=1000
            )
            raw = res.choices[0].message.content.strip()
            if raw.startswith("```"):
                raw = raw.strip("`").strip()
                if raw.lower().startswith("json"):
                    raw = raw[4:].strip()
            parsed = json.loads(raw)
            st.session_state.hook = parsed.get("hook", "")
            st.session_state.structure_titles = parsed.get("sections", [])
        except Exception as e:
            st.error("‚ùå GPT tr·∫£ v·ªÅ kh√¥ng ƒë√∫ng JSON ho·∫∑c l·ªói khi ph√¢n t√≠ch:")
            st.code(raw)

# === TI√äU ƒê·ªÄ SECTION C√ì TH·ªÇ XO√Å ===
if st.session_state.structure_titles:
    st.markdown("#### üß± Ti√™u ƒë·ªÅ c√°c section (c√≥ th·ªÉ ch·ªânh s·ª≠a ho·∫∑c xo√°):")
    for i, title in enumerate(st.session_state.structure_titles):
        col1, col2 = st.columns([5, 1])
        with col1:
            st.session_state.structure_titles[i] = st.text_input(f"Section {i+1} Title", title, key=f"title_{i}")
        with col2:
            if st.button("‚ùå", key=f"del_{i}"):
                st.session_state.structure_titles.pop(i)
                st.experimental_rerun()

# === VI·∫æT SECTION ===
st.markdown("---")
st.subheader("‚úçÔ∏è Vi·∫øt n·ªôi dung t·ª´ng Section")
style_files = list_available_style_vectors()
selected_style_file = st.selectbox("üé® Ch·ªçn phong c√°ch c√° nh√¢n:", style_files if style_files else ["Kh√¥ng t√¨m th·∫•y vector"])
word_count = st.slider("üî§ S·ªë l∆∞·ª£ng t·ª´ m·ªói section:", 100, 3000, 500, step=100)

if st.session_state.structure_titles:
    for idx, title in enumerate(st.session_state.structure_titles):
        if st.button(f"‚úçÔ∏è Vi·∫øt Section {idx+1}: {title}", key=f"gen_{idx}"):
            try:
                with st.spinner("ƒêang vi·∫øt section..."):
                    vector = load_style_vector_from_file(selected_style_file)
                    references = select_relevant_sources(title)
                    prev_title = st.session_state.sections[idx - 1]["title"] if idx > 0 and idx <= len(st.session_state.sections) else None
                    prev_content = st.session_state.sections[idx - 1]["user_edit"] if idx > 0 and idx <= len(st.session_state.sections) else None
                    examples = get_style_examples(vector)

                    prompt_parts = [
                        "You are a writing assistant trained to match this personal narrative style.",
                        "Here are example paragraphs:\n" + "\n\n".join(examples),
                        "------------------------",
                        f"Hook: {st.session_state.hook}"
                    ]
                    if prev_title and prev_content:
                        prompt_parts.append("You are continuing a multi-part narrative script.")
                        prompt_parts.append(f"Previous Section Title: {prev_title}")
                        prompt_parts.append(f"Previous Section Content: {prev_content[:600]}")
                    prompt_parts.append(f"Now, write the next section titled: '{title}'")
                    prompt_parts.append(f"References:\n{references}")
                    if strong_tone_prompt:
                        prompt_parts.append(strong_tone_prompt)
                    prompt_parts.append(
                        f"Write a vivid, immersive section of about {word_count} words in the same tone. "
                        f"Use {pov_choice} person point of view. Do NOT repeat the section title. Do NOT include the title in the content."
                    )

                    full_prompt = "\n\n".join(prompt_parts)
                    res = client.chat.completions.create(
                        model="gpt-4o",
                        messages=[{"role": "user", "content": full_prompt}],
                        temperature=0.7,
                        max_tokens=min(int(word_count * 1.5), 6000)
                    )
                    output = res.choices[0].message.content.strip()
                    if idx < len(st.session_state.sections):
                        st.session_state.sections[idx]["user_edit"] = output
                        st.session_state.sections[idx]["title"] = title
                    else:
                        st.session_state.sections.append({
                            "title": title,
                            "user_edit": output
                        })
            except Exception as e:
                st.error(f"‚ùå GPT Error: {e}")
# === HI·ªÇN TH·ªä SECTION ===
for i, sec in enumerate(st.session_state.sections):
    st.markdown(f"### üì¶ {sec['title']}")
    sec["user_edit"] = st.text_area(f"Section {i+1} - C√≥ th·ªÉ ch·ªânh s·ª≠a t·∫°i ƒë√¢y:", sec["user_edit"], height=250, key=f"edit_{i}")

# === XU·∫§T TO√ÄN B·ªò ===
st.markdown("---")
if st.button("üì§ Xu·∫•t to√†n b·ªô n·ªôi dung"):
    full_text = st.session_state.hook + "\n\n"
    for sec in st.session_state.sections:
        full_text += f"{sec['title']}\n{sec['user_edit']}\n\n"
    filename = f"ghostwriter_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    with open(filename, "w", encoding="utf-8") as f:
        f.write(full_text)
    st.success(f"‚úÖ File ƒë√£ xu·∫•t: {filename}")
