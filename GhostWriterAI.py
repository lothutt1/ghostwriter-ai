import streamlit as st
import openai
import os
import json
import numpy as np
import requests
import time
from datetime import datetime
import trafilatura
from youtube_transcript_api import YouTubeTranscriptApi
from googlesearch import search
from sentence_transformers import SentenceTransformer, util

# === C·∫•u h√¨nh OpenAI ===
client = openai.OpenAI()
st.set_page_config(page_title="GhostWriter AI", layout="wide")

STYLE_SAMPLE_DIR = "my_style_samples"
model_embed = SentenceTransformer("all-MiniLM-L6-v2")

def build_reference_vectors():
    texts = st.session_state.sources
    if not texts:
        return
    embeddings = model_embed.encode(texts, convert_to_tensor=True)
    st.session_state.source_vectors = embeddings


# === SESSION STATE ===
if "hook" not in st.session_state:
    st.session_state.hook = ""
if "sections" not in st.session_state:
    st.session_state.sections = []
if "sources" not in st.session_state:
    st.session_state.sources = []
if "structure_titles" not in st.session_state:
    st.session_state.structure_titles = []
if "source_vectors" not in st.session_state:
    st.session_state.source_vectors = []

# === C√ÅC TONE PHONG C√ÅCH ƒê·ªäNH S·∫¥N ===
persona_tones = {
    "Gi√°o s∆∞ ch√¢m bi·∫øm": "witty, sarcastic, intellectually playful",
    "ASMR nh·∫π nh√†ng": "calm, sensory, soothing and immersive",
    "H√†i h∆∞·ªõc ph√≥ng ƒë·∫°i": "goofy, absurd, highly exaggerated and comedic",
    "K·ªÉ nh∆∞ b·∫°n th√¢n": "casual, relatable, conversational",
    "Kinh d·ªã th√¨ th·∫ßm": "dark, suspenseful, vivid and unsettling",
    "S·ª≠ chu·∫©n gi√°o s∆∞": "formal, precise, informative",
    "Tri·∫øt l√Ω huy·ªÅn b√≠": "poetic, reflective, symbolic and deep"
}

# === STYLE VECTOR ===
def list_available_style_vectors():
    return [f for f in os.listdir() if f.startswith("my_style_vector") and f.endswith(".json")]

def load_style_vector_from_file(file):
    with open(file, "r", encoding="utf-8") as f:
        return np.array(json.load(f))

# === TMProxy cache h·ªó tr·ª£ ===
tmproxy_api_key = st.secrets["TM_PROXY_API_KEY"]
def get_tmproxy_with_cache(api_key):

    if "tmproxy" not in st.session_state:
        st.session_state.tmproxy = {}

    cache = st.session_state.tmproxy
    now = time.time()

    # N·∫øu c√≤n hi·ªáu l·ª±c th√¨ d√πng l·∫°i
    if cache and now < cache.get("expires_at", 0) - 30:
        return cache["proxy_url"]

    try:
        url = "https://tmproxy.com/api/proxy/get-new-proxy"
        headers = {"accept": "application/json", "Content-Type": "application/json"}
        data = {"api_key": api_key, "id_location": 0, "id_isp": 0}

        res = requests.post(url, headers=headers, json=data, timeout=10)
        res.raise_for_status()
        res_json = res.json()

        # N·∫øu th√†nh c√¥ng ‚Üí l∆∞u v√† tr·∫£ proxy m·ªõi
        if res_json["code"] == 0:
            proxy = res_json["data"]
            proxy_url = f"http://{proxy['username']}:{proxy['password']}@{proxy['https']}"
            expires_at = now + proxy["timeout"]

            st.session_state.tmproxy = {
                "proxy_url": proxy_url,
                "expires_at": expires_at
            }

            return proxy_url

        # N·∫øu b·ªã gi·ªõi h·∫°n th·ªùi gian ‚Üí d√πng l·∫°i proxy c≈© n·∫øu c√≥
        elif "retry after" in res_json.get("message", "").lower():
            if cache.get("proxy_url"):
                wait_msg = res_json["message"]
                st.info(f"üîÅ {wait_msg}. ƒêang d√πng l·∫°i proxy c≈©.")
                return cache["proxy_url"]
            else:
                raise Exception(f"TMProxy ch∆∞a c√≥ proxy tr∆∞·ªõc ƒë√≥ ƒë·ªÉ d√πng l·∫°i.")

        else:
            raise Exception(f"TMProxy Error: {res_json.get('message')}")

    except Exception as e:
        st.error(f"‚ùå Kh√¥ng th·ªÉ l·∫•y proxy t·ª´ TMProxy: {e}")
        return None

# === GIAO DI·ªÜN CH√çNH ===
st.title("üìù GhostWriter AI")
topic = st.text_input("üéØ Nh·∫≠p ch·ªß ƒë·ªÅ ho·∫∑c n·ªôi dung video:")
pov_choice = st.selectbox("üë§ Ch·ªçn ng√¥i k·ªÉ:", ["first", "second", "third"], index=1)

selected_personas = st.multiselect("üé≠ Ch·ªçn c√°c phong c√°ch h√†nh vƒÉn mu·ªën k·∫øt h·ª£p:", list(persona_tones.keys()))
style_tone_instruction = ", ".join([persona_tones[p] for p in selected_personas]) if selected_personas else ""
strong_tone_prompt = ""
if style_tone_instruction:
    strong_tone_prompt = (
        f"Write this section in a distinctly {style_tone_instruction} tone.\n"
        f"Channel the spirit of a narrator who embodies these traits in full.\n"
        f"Avoid solemn or overly poetic language unless it enhances the comedic or satirical effect."
    )

# === NGU·ªíN THAM KH·∫¢O GOOGLE ===
if st.button("üîé T√¨m link Google"):
    with st.spinner("ƒêang t√¨m ki·∫øm tr√™n Google..."):
        try:
            results = list(search(topic, num_results=25))
            st.session_state.search_links = results
        except Exception as e:
            st.error(f"L·ªói Google Search: {e}")

if "search_links" in st.session_state:
    selected_links = st.multiselect("Ch·ªçn link ƒë·ªÉ tr√≠ch n·ªôi dung:", st.session_state.search_links)

    if st.button("üìÑ Tr√≠ch n·ªôi dung t·ª´ link ƒë√£ ch·ªçn"):
        try:
            proxy_url = get_tmproxy_with_cache(tmproxy_api_key)

            if proxy_url:
                proxy_dict = {"http": proxy_url, "https": proxy_url}

                # L√†m s·∫°ch tr∆∞·ªõc khi th√™m m·ªõi
                st.session_state.sources = []

                for link in selected_links:
                    try:
                        response = requests.get(link, proxies=proxy_dict, timeout=10)
                        text = trafilatura.extract(response.text)
                        if text:
                            st.session_state.sources.append(f"[SOURCE: {link}]\n{text.strip()}")
                        else:
                            st.warning(f"‚ö†Ô∏è Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c n·ªôi dung t·ª´: {link}")
                    except requests.exceptions.RequestException as e:
                        st.warning(f"‚ö†Ô∏è L·ªói khi truy c·∫≠p {link}: {e}")

                build_reference_vectors()
                st.success("‚úÖ ƒê√£ t·∫°o vector t·ª´ ngu·ªìn tham kh·∫£o!")

            else:
                st.warning("‚ö†Ô∏è Kh√¥ng c√≥ proxy h·ª£p l·ªá. D·ª´ng ti·∫øn tr√¨nh.")
        except Exception as e:
            st.error(f"‚ùå L·ªói proxy khi tr√≠ch Google: {e}")


# === L·∫§Y CAPTION YOUTUBE ===
from urllib.parse import urlparse, parse_qs
from youtube_transcript_api import YouTubeTranscriptApi, CouldNotRetrieveTranscript

yt_url = st.text_input("Link YouTube")

if st.button("üé¨ L·∫•y caption") and yt_url:
    try:
        video_id = parse_qs(urlparse(yt_url).query).get("v", [""])[0]
        proxy_url = get_tmproxy_with_cache(tmproxy_api_key)

        if proxy_url:
            proxies = {"http": proxy_url, "https": proxy_url}
            transcript = YouTubeTranscriptApi.get_transcript(video_id, proxies=proxies)
            full_text = " ".join([x['text'] for x in transcript])

            st.session_state.sources.append(f"[YOUTUBE]\n{full_text.strip()}")
            build_reference_vectors()
            st.success("‚úÖ ƒê√£ l·∫•y caption t·ª´ YouTube qua TMProxy!")
        else:
            st.warning("‚ö†Ô∏è Kh√¥ng c√≥ proxy h·ª£p l·ªá. D·ª´ng ti·∫øn tr√¨nh.")

    except CouldNotRetrieveTranscript:
        st.error("‚ùå Video kh√¥ng h·ªó tr·ª£ ph·ª• ƒë·ªÅ ho·∫∑c kh√¥ng th·ªÉ l·∫•y caption.")
    except Exception as e:
        st.error(f"‚ùå L·ªói l·∫•y caption: {e}")


# === BUILD VECTOR ===
def build_reference_vectors():
    chunks = []
    for src in st.session_state.sources:
        # B·ªè d√≤ng ƒë·∫ßu n·∫øu ch·ª©a metadata
        if src.startswith("[SOURCE:") or src.startswith("[YOUTUBE]"):
            src = "\n".join(src.split("\n")[1:])

        paragraphs = src.split("\n")
        for p in paragraphs:
            p = p.strip()
            if len(p) > 100:
                chunks.append(p)

    st.session_state.source_vectors = [
        (text, model_embed.encode(text, convert_to_tensor=False)) for text in chunks
    ]

def select_relevant_sources(title, top_k=1):
    title_vec = model_embed.encode(title, convert_to_tensor=False)
    scores = [(text, float(util.cos_sim(title_vec, vec))) for text, vec in st.session_state.source_vectors]
    scores.sort(key=lambda x: -x[1])
    return "\n\n".join([s[0] for s in scores[:top_k]])


# === T·∫†O HOOK ===
st.markdown("---")
st.subheader("‚ú® Vi·∫øt Hook m·ªü ƒë·∫ßu video")

if st.button("üß† T·∫°o Hook m·ªü ƒë·∫ßu"):
    with st.spinner("ƒêang t·∫°o hook..."):

        # ‚úÖ An to√†n h∆°n khi check session_state
        if not st.session_state.get("source_vectors"):
            build_reference_vectors()

        refs = select_relevant_sources(topic, top_k=3)

        prompt = f"""
You are a creative ASMR-style content writer. Write a vivid, immersive, slightly witty YouTube hook intro for:
"{topic}"

References:
{refs}

Follow this format:
- Open with "Hey guys, tonight we..."
- Use vivid sensory imagery
- Include a funny warning: "you probably won't survive this..."
- End with a cozy CTA to like & relax
"""

        try:
            res = client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=500
            )
            st.session_state.hook = res.choices[0].message.content.strip()

        except Exception as e:
            st.error(f"‚ùå GPT Error khi t·∫°o hook: {e}")

st.text_area("‚ú® Hook m·ªü ƒë·∫ßu:", st.session_state.hook, height=150, key="hook_textarea")


# === G·ª¢I √ù C·∫§U TR√öC N·ªòI DUNG ===
st.markdown("---")
st.subheader("üìö G·ª£i √Ω c·∫•u tr√∫c n·ªôi dung")
num_sections = st.slider("üìë S·ªë l∆∞·ª£ng section mong mu·ªën:", min_value=3, max_value=10, value=6, step=1)

if st.button("‚öôÔ∏è G·ª£i √Ω l·∫°i c·∫•u tr√∫c"):
    with st.spinner("ƒêang sinh c·∫•u tr√∫c ƒë·ªÅ xu·∫•t..."):

        # ƒê·∫£m b·∫£o ƒë√£ build vector tr∆∞·ªõc khi ch·ªçn ngu·ªìn
        if "source_vectors" not in st.session_state or not st.session_state.source_vectors:
            build_reference_vectors()

        refs = select_relevant_sources(topic, top_k=3)  # ch·ªçn 3 ƒëo·∫°n tham kh·∫£o s√°t topic
        raw = ""  # tr√°nh l·ªói n·∫øu parsing th·∫•t b·∫°i

        prompt = f"""
You are a YouTube script planner. Based on the topic below, generate a hook and exactly {num_sections} section titles in order.

Only return pure JSON. No explanation. Format:
{{
  "hook": "...",
  "sections": ["...", "...", "..."]
}}

Topic: {topic}
References:
{refs}
"""

        try:
            res = client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.6,
                max_tokens=1000
            )
            raw = res.choices[0].message.content.strip()

            # G·ª° b·ªè markdown n·∫øu c√≥
            if raw.startswith("```"):
                raw = raw.strip("`").strip()
                if raw.lower().startswith("json"):
                    raw = raw[4:].strip()

            parsed = json.loads(raw)

            st.session_state.hook = parsed.get("hook", "")
            titles = parsed.get("sections", [])
            st.session_state.structure_titles = [(title, "") for title in titles]  # gi·ªØ ƒë√∫ng ƒë·ªãnh d·∫°ng

        except Exception as e:
            st.error("‚ùå GPT tr·∫£ v·ªÅ kh√¥ng ƒë√∫ng JSON ho·∫∑c l·ªói khi ph√¢n t√≠ch:")
            st.code(raw if raw else "Kh√¥ng c√≥ ph·∫£n h·ªìi h·ª£p l·ªá t·ª´ GPT.")


# === SECTION TI√äU ƒê·ªÄ ===
if st.session_state.structure_titles:
    st.markdown("#### üß± Ti√™u ƒë·ªÅ c√°c section (c√≥ th·ªÉ ch·ªânh s·ª≠a ho·∫∑c xo√°):")

    for i, (title, prompt) in enumerate(st.session_state.structure_titles):
        col1, col2 = st.columns([5, 1])

        with col1:
            new_title = st.text_input(f"Section {i+1} Title", title, key=f"title_{i}")
            st.session_state.structure_titles[i] = (new_title, prompt)  # c·∫≠p nh·∫≠t title, gi·ªØ nguy√™n prompt

        with col2:
            if st.button("‚ùå", key=f"del_{i}"):
                st.session_state.structure_titles.pop(i)
                st.experimental_rerun()


# === VI·∫æT N·ªòI DUNG M·ªñI SECTION ===
st.markdown("---")
st.subheader("‚úçÔ∏è Vi·∫øt n·ªôi dung t·ª´ng Section")

style_files = list_available_style_vectors()
selected_style_file = st.selectbox("üé® Ch·ªçn phong c√°ch c√° nh√¢n:", style_files if style_files else ["Kh√¥ng t√¨m th·∫•y vector"])
word_count = st.slider("üî§ S·ªë l∆∞·ª£ng t·ª´ m·ªói section:", 100, 3000, 500, step=100)

# H√†m fallback n·∫øu thi·∫øu
def get_style_examples(vector, sample_count=3):
    try:
        if isinstance(vector, (list, np.ndarray)):
            return vector[:sample_count]
    except:
        return []
    return []

# N·∫øu c√≥ danh s√°ch section c·∫ßn vi·∫øt
if st.session_state.structure_titles:
    for idx, (title, prompt) in enumerate(st.session_state.structure_titles):
        if st.button(f"‚úçÔ∏è Vi·∫øt Section {idx+1}: {title}", key=f"gen_{idx}"):
            try:
                with st.spinner("ƒêang vi·∫øt section..."):
                    vector = load_style_vector_from_file(selected_style_file)
                    references = select_relevant_sources(prompt)

                    # L·∫•y section tr∆∞·ªõc ƒë√≥ n·∫øu c√≥
                    prev_title = st.session_state.sections[idx - 1]["title"] if idx > 0 and idx <= len(st.session_state.sections) else None
                    prev_content = st.session_state.sections[idx - 1]["user_edit"] if idx > 0 and idx <= len(st.session_state.sections) else None

                    examples = get_style_examples(vector)

                    # T·∫°o prompt ƒë·∫ßy ƒë·ªß
                    prompt_parts = [
                        "You are a writing assistant trained to match this personal narrative style.",
                        "Here are example paragraphs:\n" + "\n\n".join(examples),
                        "------------------------",
                        f"Hook: {st.session_state.hook}",
                        f"Section Title: {title}",
                        f"Section Prompt: {prompt}",
                    ]

                    if prev_title and prev_content:
                        prompt_parts.append("You are continuing a multi-part narrative script.")
                        prompt_parts.append(f"Previous Section Title: {prev_title}")
                        prompt_parts.append(f"Previous Section Content: {prev_content[:600]}")

                    prompt_parts.append(f"References:\n{references}")

                    # B·ªï sung gi·ªçng ƒëi·ªáu n·∫øu c√≥
                    if 'strong_tone_prompt' in globals():
                        prompt_parts.append(strong_tone_prompt)
                    else:
                        prompt_parts.append("Maintain consistent tone with the provided examples.")

                    if 'pov_choice' in globals():
                        prompt_parts.append(
                            f"Write a vivid, immersive section of about {word_count} words. "
                            f"Use {pov_choice} person point of view. "
                            f"Do NOT include the title in the content."
                        )
                    else:
                        prompt_parts.append(
                            f"Write a vivid, immersive section of about {word_count} words in the same tone. "
                            f"Do NOT include the title in the content."
                        )

                    # G·ª≠i y√™u c·∫ßu ƒë·∫øn GPT
                    full_prompt = "\n\n".join(prompt_parts)
                    res = client.chat.completions.create(
                        model="gpt-4o",
                        messages=[{"role": "user", "content": full_prompt}],
                        temperature=0.7,
                        max_tokens=min(int(word_count * 1.5), 6000)
                    )

                    output = res.choices[0].message.content.strip()

                    if idx < len(st.session_state.sections):
                        st.session_state.sections[idx]["user_edit"] = output
                        st.session_state.sections[idx]["title"] = title
                    else:
                        st.session_state.sections.append({
                            "title": title,
                            "user_edit": output
                        })

            except Exception as e:
                st.error(f"‚ùå GPT Error: {e}")


# === HI·ªÇN TH·ªä SECTION ===
for i, sec in enumerate(st.session_state.sections):
    st.markdown(f"### üì¶ {sec['title']}")
    sec["user_edit"] = st.text_area(f"Section {i+1} - C√≥ th·ªÉ ch·ªânh s·ª≠a t·∫°i ƒë√¢y:", sec["user_edit"], height=250, key=f"edit_{i}")

# === XU·∫§T TO√ÄN B·ªò ===
st.markdown("---")
if st.session_state.sections:
    full_text = st.session_state.hook + "\n\n"
    for sec in st.session_state.sections:
        full_text += f"{sec['title']}\n{sec['user_edit']}\n\n"

    filename = f"ghostwriter_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"

    st.download_button(
        label="üì• T·∫£i to√†n b·ªô n·ªôi dung (.txt)",
        data=full_text,
        file_name=filename,
        mime="text/plain"
    )

